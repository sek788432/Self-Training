{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799912af",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a0e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from functools import partial\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb56c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU 0: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-b40ca8d0-abdc-cfcd-8b26-ab0e1c48f616)\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292333be",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68586be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"E:/Old data/CTU13+PeerRush/dnn_input/1-1/CTU13_all_training_shuf\"\n",
    "test_path = \"E:/Old data/CTU13+PeerRush/dnn_input/1-1/CTU13_all_testing_shuf\"\n",
    "train_data = open(test_path, 'r')\n",
    "test_data = open(train_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54f4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(data):\n",
    "    '''\n",
    "    the function reads in raw data and outputs dataframe format\n",
    "    '''\n",
    "    output = []\n",
    "    for line in data:\n",
    "        cols = line.split(',')\n",
    "        cols[-1] = cols[-1].rstrip()         #remove \\n\n",
    "        output.append(cols)\n",
    "    print(\"Number of sessions: \", len(output))       \n",
    "    print(\"Number of features: \", len(output[0])-2)   \n",
    "    output = pd.DataFrame(output, columns = [\"IP pair\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\", \"f9\",\n",
    "                                      \"f10\", \"f11\", \"f12\", \"f13\", \"f14\", \"label\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e09e8",
   "metadata": {},
   "source": [
    "# Combine and Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1ae3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions:  4582\n",
      "Number of features:  14\n",
      "Number of sessions:  1472\n",
      "Number of features:  14\n"
     ]
    }
   ],
   "source": [
    "df_train = make_dataframe(train_data)\n",
    "df_test = make_dataframe(test_data)\n",
    "df_combine = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65041d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IP pair</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147.32.84.191&gt;81.167.10.130</td>\n",
       "      <td>2</td>\n",
       "      <td>652</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326.0</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131.0</td>\n",
       "      <td>783</td>\n",
       "      <td>326</td>\n",
       "      <td>261.0</td>\n",
       "      <td>91.92388</td>\n",
       "      <td>0.200920245398773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147.32.84.191&gt;121.54.32.135</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>504</td>\n",
       "      <td>126</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147.32.84.192&gt;110.18.224.196</td>\n",
       "      <td>4</td>\n",
       "      <td>360</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>360</td>\n",
       "      <td>90</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147.32.84.165&gt;211.140.199.130</td>\n",
       "      <td>4</td>\n",
       "      <td>444</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111.0</td>\n",
       "      <td>221</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110.0</td>\n",
       "      <td>665</td>\n",
       "      <td>111</td>\n",
       "      <td>110.66667</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.49774774774774777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147.32.84.191&gt;84.52.163.247</td>\n",
       "      <td>8</td>\n",
       "      <td>2328</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291.0</td>\n",
       "      <td>632</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2960</td>\n",
       "      <td>291</td>\n",
       "      <td>246.66667</td>\n",
       "      <td>62.6968</td>\n",
       "      <td>0.27147766323024053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>147.32.84.165&gt;60.160.108.251</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76.0</td>\n",
       "      <td>226</td>\n",
       "      <td>76</td>\n",
       "      <td>75.33333</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.5066666666666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>147.32.84.192&gt;89.208.180.60</td>\n",
       "      <td>24</td>\n",
       "      <td>2240</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93.0</td>\n",
       "      <td>18650</td>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "      <td>981.0</td>\n",
       "      <td>20890</td>\n",
       "      <td>981</td>\n",
       "      <td>485.37209</td>\n",
       "      <td>440.98816</td>\n",
       "      <td>8.325892857142858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>147.32.84.192&gt;94.251.103.230</td>\n",
       "      <td>2</td>\n",
       "      <td>252</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126.0</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319.0</td>\n",
       "      <td>571</td>\n",
       "      <td>319</td>\n",
       "      <td>190.33333</td>\n",
       "      <td>90.98107</td>\n",
       "      <td>1.2658730158730158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>147.32.84.191&gt;195.138.217.171</td>\n",
       "      <td>2</td>\n",
       "      <td>652</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326.0</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131.0</td>\n",
       "      <td>783</td>\n",
       "      <td>326</td>\n",
       "      <td>261.0</td>\n",
       "      <td>91.92388</td>\n",
       "      <td>0.200920245398773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>147.32.84.191&gt;79.105.176.89</td>\n",
       "      <td>4</td>\n",
       "      <td>432</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108.0</td>\n",
       "      <td>419</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>209.0</td>\n",
       "      <td>851</td>\n",
       "      <td>209</td>\n",
       "      <td>141.66667</td>\n",
       "      <td>47.61186</td>\n",
       "      <td>0.9699074074074074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6054 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            IP pair  f1    f2   f3   f4     f5     f6   f7  \\\n",
       "0       147.32.84.191>81.167.10.130   2   652  326  326  326.0    131  131   \n",
       "1       147.32.84.191>121.54.32.135   4   504  126  126  126.0      0   -1   \n",
       "2      147.32.84.192>110.18.224.196   4   360   90   90   90.0      0   -1   \n",
       "3     147.32.84.165>211.140.199.130   4   444  111  111  111.0    221  110   \n",
       "4       147.32.84.191>84.52.163.247   8  2328  291  291  291.0    632  158   \n",
       "...                             ...  ..   ...  ...  ...    ...    ...  ...   \n",
       "1467   147.32.84.165>60.160.108.251   2   150   75   75   75.0     76   76   \n",
       "1468    147.32.84.192>89.208.180.60  24  2240   93   93   93.0  18650  981   \n",
       "1469   147.32.84.192>94.251.103.230   2   252  126  126  126.0    319  319   \n",
       "1470  147.32.84.191>195.138.217.171   2   652  326  326  326.0    131  131   \n",
       "1471    147.32.84.191>79.105.176.89   4   432  108  108  108.0    419  209   \n",
       "\n",
       "       f8     f9    f10  f11        f12        f13                  f14 label  \n",
       "0     131  131.0    783  326      261.0   91.92388    0.200920245398773     0  \n",
       "1      -1   -1.0    504  126      126.0        0.0                  0.0     1  \n",
       "2      -1   -1.0    360   90       90.0        0.0                  0.0     1  \n",
       "3     110  110.0    665  111  110.66667     0.4714  0.49774774774774777     0  \n",
       "4     158  158.0   2960  291  246.66667    62.6968  0.27147766323024053     0  \n",
       "...   ...    ...    ...  ...        ...        ...                  ...   ...  \n",
       "1467   76   76.0    226   76   75.33333     0.4714   0.5066666666666667     1  \n",
       "1468  981  981.0  20890  981  485.37209  440.98816    8.325892857142858     1  \n",
       "1469  319  319.0    571  319  190.33333   90.98107   1.2658730158730158     1  \n",
       "1470  131  131.0    783  326      261.0   91.92388    0.200920245398773     0  \n",
       "1471  209  209.0    851  209  141.66667   47.61186   0.9699074074074074     1  \n",
       "\n",
       "[6054 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f6302f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_(df):\n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled)\n",
    "    return df\n",
    "df_combine.iloc[:, 1:-1] = normalize_(df_combine.iloc[:, 1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73e55e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IP pair</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147.32.84.191&gt;81.167.10.130</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.220868</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147.32.84.191&gt;121.54.32.135</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.082183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147.32.84.192&gt;110.18.224.196</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.045201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147.32.84.165&gt;211.140.199.130</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.034515</td>\n",
       "      <td>0.034515</td>\n",
       "      <td>0.034515</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.066432</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.00307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147.32.84.191&gt;84.52.163.247</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.04944</td>\n",
       "      <td>0.04944</td>\n",
       "      <td>0.04944</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.043317</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>147.32.84.165&gt;60.160.108.251</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.030134</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>147.32.84.192&gt;89.208.180.60</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.305348</td>\n",
       "      <td>0.305348</td>\n",
       "      <td>0.305348</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.251277</td>\n",
       "      <td>0.451363</td>\n",
       "      <td>0.304675</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>147.32.84.192&gt;94.251.103.230</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.073367</td>\n",
       "      <td>0.148272</td>\n",
       "      <td>0.062858</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>147.32.84.191&gt;195.138.217.171</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>0.220868</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>147.32.84.191&gt;79.105.176.89</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.043805</td>\n",
       "      <td>0.098278</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6054 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            IP pair        f1        f2        f3        f4  \\\n",
       "0       147.32.84.191>81.167.10.130  0.000105  0.000058  0.075249  0.075249   \n",
       "1       147.32.84.191>121.54.32.135  0.000314  0.000044    0.0215    0.0215   \n",
       "2      147.32.84.192>110.18.224.196  0.000314   0.00003  0.011825  0.011825   \n",
       "3     147.32.84.165>211.140.199.130  0.000314  0.000038  0.017468  0.017468   \n",
       "4       147.32.84.191>84.52.163.247  0.000733   0.00022  0.065843  0.065843   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "1467   147.32.84.165>60.160.108.251  0.000105   0.00001  0.007794  0.007794   \n",
       "1468    147.32.84.192>89.208.180.60  0.002408  0.000212  0.012631  0.012631   \n",
       "1469   147.32.84.192>94.251.103.230  0.000105   0.00002    0.0215    0.0215   \n",
       "1470  147.32.84.191>195.138.217.171  0.000105  0.000058  0.075249  0.075249   \n",
       "1471    147.32.84.191>79.105.176.89  0.000314  0.000037  0.016662  0.016662   \n",
       "\n",
       "            f5        f6        f7        f8        f9       f10       f11  \\\n",
       "0     0.075249  0.000016  0.041045  0.041045  0.041045   0.00007  0.075249   \n",
       "1       0.0215       0.0       0.0       0.0       0.0  0.000043    0.0215   \n",
       "2     0.011825       0.0       0.0       0.0       0.0  0.000029  0.011825   \n",
       "3     0.017468  0.000028  0.034515  0.034515  0.034515  0.000058  0.017468   \n",
       "4     0.065843  0.000079   0.04944   0.04944   0.04944  0.000277  0.065843   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1467  0.007794   0.00001  0.023943  0.023943  0.023943  0.000016  0.008062   \n",
       "1468  0.012631  0.002341  0.305348  0.305348  0.305348  0.001989  0.251277   \n",
       "1469    0.0215   0.00004  0.099502  0.099502  0.099502  0.000049  0.073367   \n",
       "1470  0.075249  0.000016  0.041045  0.041045  0.041045   0.00007  0.075249   \n",
       "1471  0.016662  0.000053  0.065299  0.065299  0.065299  0.000076  0.043805   \n",
       "\n",
       "           f12       f13       f14 label  \n",
       "0     0.220868  0.063509  0.001239     0  \n",
       "1     0.082183       0.0       0.0     1  \n",
       "2     0.045201       0.0       0.0     1  \n",
       "3     0.066432  0.000326   0.00307     0  \n",
       "4     0.206143  0.043317  0.001674     0  \n",
       "...        ...       ...       ...   ...  \n",
       "1467  0.030134  0.000326  0.003125     1  \n",
       "1468  0.451363  0.304675  0.051354     1  \n",
       "1469  0.148272  0.062858  0.007808     1  \n",
       "1470  0.220868  0.063509  0.001239     0  \n",
       "1471  0.098278  0.032895  0.005982     1  \n",
       "\n",
       "[6054 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e11bdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_combine, test_size=0.95, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b37a27",
   "metadata": {},
   "source": [
    "# Proportion of Malicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc5cc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious proportion:  24.297984803435746  %\n"
     ]
    }
   ],
   "source": [
    "# proportion of benign and malicious\n",
    "def get_proportion():\n",
    "    n_0, n_1 = 0, 0\n",
    "    for i in df_combine['label']:\n",
    "        if i == '0':\n",
    "            n_0 += 1\n",
    "        else:\n",
    "            n_1 += 1\n",
    "    print(\"Malicious proportion: \", n_1 / (n_0+n_1) * 100, \" %\")\n",
    "get_proportion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3689f51",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ecb5514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x:  (302, 14)\n",
      "train y:  (302,)\n",
      "test x:  (5752, 14)\n",
      "test y:  (5752,)\n"
     ]
    }
   ],
   "source": [
    "train_y = np.array(df_train['label']).astype(np.float)\n",
    "train_x = np.array(df_train.iloc[:, 1:-1]).astype(np.float)\n",
    "test_y = np.array(df_test['label']).astype(np.float)\n",
    "test_x = np.array(df_test.iloc[:, 1:-1]).astype(np.float)\n",
    "print(\"train x: \", train_x.shape)\n",
    "print(\"train y: \", train_y.shape)\n",
    "print(\"test x: \", test_x.shape)\n",
    "print(\"test y: \", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d543f9",
   "metadata": {},
   "source": [
    "# Model Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed964dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(train_x, output_class = 2, neurons = 4096, drop_rate = 0.4, weights = None):\n",
    "    \n",
    "    '''\n",
    "    1. 6 fully connect layers with 4096 neurons as default\n",
    "    2. set dropout layers at last 3 hidden layers\n",
    "    3. load weights if weight not none\n",
    "    '''\n",
    "    \n",
    "    input_features = train_x.shape[1]\n",
    "    RegularizedDense = partial(Dense, \n",
    "                              activation = 'relu', \n",
    "                              kernel_initializer = 'he_normal')\n",
    "    model = Sequential([\n",
    "        Input(shape = (input_features, )),\n",
    "        RegularizedDense(neurons),\n",
    "        RegularizedDense(neurons),\n",
    "        RegularizedDense(neurons),\n",
    "        RegularizedDense(neurons),\n",
    "        Dropout(drop_rate),\n",
    "        RegularizedDense(neurons),\n",
    "        Dropout(drop_rate),\n",
    "        RegularizedDense(neurons),\n",
    "        Dropout(drop_rate),\n",
    "        RegularizedDense(output_class, activation = 'softmax')\n",
    "    ])\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "666eb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_x, train_y,\n",
    "                lr, epochs, batch, early_p = 30,\n",
    "                lr_p = 9, min_lr = 1e-7, lr_factor = 0.1):\n",
    "    \n",
    "    '''\n",
    "    1. validation data is always set to 0.2 of training data\n",
    "    2. earlystopping and learning rate scheduler to improve accuracy\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    callback = EarlyStopping(monitor='val_accuracy', patience=early_p, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=lr_factor, patience=lr_p, verbose=1, min_lr=min_lr)\n",
    "    opt = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_x, train_y,\n",
    "                        callbacks=[callback, reduce_lr],\n",
    "                        shuffle=True,\n",
    "                        epochs=epochs,\n",
    "                        batch_size = batch,\n",
    "                        validation_split=0.2)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c90950",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c5ba33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4096)              61440     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 83,976,194\n",
      "Trainable params: 83,976,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = dnn_model(train_x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f745c",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96b0938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "early_patience = 15\n",
    "learning_rate_patience = 2\n",
    "lr_factor = 0.3\n",
    "min_learning_rate = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2369f0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 4s 88ms/step - loss: 4.8615 - accuracy: 0.6827 - val_loss: 0.2682 - val_accuracy: 0.8852\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.4069 - accuracy: 0.8171 - val_loss: 0.3014 - val_accuracy: 0.8852\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.6377 - accuracy: 0.8987 - val_loss: 0.1564 - val_accuracy: 0.9016\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2927 - accuracy: 0.8854 - val_loss: 0.4007 - val_accuracy: 0.8852\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2794 - accuracy: 0.9003 - val_loss: 0.4692 - val_accuracy: 0.8852\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3033 - accuracy: 0.8658 - val_loss: 0.1463 - val_accuracy: 0.9016\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2679 - accuracy: 0.8955 - val_loss: 0.1531 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2271 - accuracy: 0.8722 - val_loss: 0.1564 - val_accuracy: 0.9016\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2418 - accuracy: 0.8940 - val_loss: 0.1578 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2332 - accuracy: 0.8908 - val_loss: 0.1582 - val_accuracy: 0.9016\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2032 - accuracy: 0.9018 - val_loss: 0.1589 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1909 - accuracy: 0.9167 - val_loss: 0.1592 - val_accuracy: 0.9016\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1887 - accuracy: 0.9108 - val_loss: 0.1596 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 5e-06.\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1835 - accuracy: 0.9191 - val_loss: 0.1599 - val_accuracy: 0.9016\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2432 - accuracy: 0.8850 - val_loss: 0.1599 - val_accuracy: 0.9016\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1963 - accuracy: 0.9136 - val_loss: 0.1599 - val_accuracy: 0.9016\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2112 - accuracy: 0.8969 - val_loss: 0.1602 - val_accuracy: 0.9016\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1674 - accuracy: 0.9315 - val_loss: 0.1603 - val_accuracy: 0.9016\n",
      "Total Execution Time:  10.571574449539185\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "history = train_model(model, train_x, train_y, lr = learning_rate,\n",
    "                      epochs = epochs, batch = batch_size, \n",
    "                      early_p = early_patience, lr_p = learning_rate_patience, \n",
    "                      min_lr = min_learning_rate, lr_factor = lr_factor)\n",
    "t2 = time()\n",
    "print(\"Total Execution Time: \",t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649d7b",
   "metadata": {},
   "source": [
    "# Performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43546b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 0s - loss: 0.2548 - accuracy: 0.8634\n",
      "Accuracy:  0.8633518815040588\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_x, test_y, verbose=2)\n",
    "best_score = result[1]\n",
    "print(\"Accuracy: \",best_score)\n",
    "model.save_weights('./self_train_best_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1122f",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c19ec5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "427ac74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65324d6",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d4f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.87      0.96      0.91      4354\n",
      "   Malicious       0.81      0.57      0.67      1398\n",
      "\n",
      "    accuracy                           0.86      5752\n",
      "   macro avg       0.84      0.76      0.79      5752\n",
      "weighted avg       0.86      0.86      0.85      5752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dict = ['Benign', 'Malicious']\n",
    "predictions = model.predict(test_x)\n",
    "y_pred = np.argmax(predictions, axis=-1)\n",
    "print(classification_report(test_y, y_pred, target_names = label_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46232bc6",
   "metadata": {},
   "source": [
    "# Confident Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5e69419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5752, 2)\n",
      "Confident Samples:  2994\n",
      "Unconfident Samples:  2758\n"
     ]
    }
   ],
   "source": [
    "unconfident, confident = 0, 0\n",
    "threshold = 0.99\n",
    "for softmax in predictions:\n",
    "    if max(softmax) > threshold:\n",
    "        confident += 1\n",
    "    else:\n",
    "        unconfident += 1\n",
    "print(predictions.shape)\n",
    "print(\"Confident Samples: \",confident)\n",
    "print(\"Unconfident Samples: \",unconfident)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08cb63",
   "metadata": {},
   "source": [
    "# Self-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "246f5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_train(model, test_x, test_y,\n",
    "               train_x, train_y, self_train_epoch, model_epoch,\n",
    "               BATCH, lr_, best_score, proportion):\n",
    "    \n",
    "    # Pseudo label\n",
    "    # Tune model with pseudo label and training data\n",
    "    \n",
    "    assert(len(proportion) == self_train_epoch)\n",
    "    \n",
    "    for i in range(self_train_epoch):\n",
    "        print('Predict Pseudo labels...\\n')\n",
    "        predictions = model.predict(test_x, verbose=1, batch_size = BATCH*4) \n",
    "        \n",
    "        # (data_len, 1) -> get the biggest confidence of all samples\n",
    "        confidence = np.amax(predictions, axis=1)\n",
    "        confidence = sorted(confidence, reverse = True)\n",
    "        \n",
    "        # proportion of the index\n",
    "        #ind = min(len(test_x)-1, int(len(test_x) * ((i+1)/self_train_epoch)))\n",
    "        ind =  min(len(test_x)-1, int(len(test_x) * proportion[i]))\n",
    "        threshold = confidence[ind]\n",
    "        print(\"threshold:\", threshold)\n",
    "        \n",
    "        x, y, act_y = [],[],[]\n",
    "        for ind, data in enumerate(test_x):\n",
    "            if max(predictions[ind]) >= threshold:\n",
    "                x.append(data)\n",
    "                y.append(np.argmax(predictions[ind]))\n",
    "                act_y.append(test_y[ind])\n",
    "        pselabel_x = np.array(x)\n",
    "        pselabel_y = np.array(y)\n",
    "        err = 0\n",
    "        for a,b in zip(y, act_y):\n",
    "            if a != b:\n",
    "                err += 1\n",
    "                \n",
    "        print(\"Pseudo label accuracy: \", (len(x) -err)/len(x))\n",
    "        del x\n",
    "        del y \n",
    "        del act_y\n",
    "        \n",
    "        # check if class disapeear at pseudo label examples\n",
    "        if tf.keras.utils.to_categorical(pselabel_y).shape[1] != 2:    \n",
    "            break\n",
    "\n",
    "        # combine pseudo label & ground truth label\n",
    "        combine_x = np.concatenate((pselabel_x, train_x), axis=0)\n",
    "        combine_y = np.concatenate((pselabel_y, train_y), axis=0)\n",
    "        print(\"Combine data shape: \",combine_x.shape)\n",
    "        print(\"Combine label shape: \",combine_y.shape,\"\\n\")\n",
    "        \n",
    "        del pselabel_x\n",
    "        del pselabel_y\n",
    "        \n",
    "        print('Tune model using pseudo-labeled data & training data...\\n')\n",
    "        model.compile(optimizer=Adam(lr=lr_), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(combine_x, combine_y, \n",
    "                            epochs =  model_epoch, \n",
    "                            verbose = 2,\n",
    "                            batch_size = BATCH, shuffle = True)\n",
    "        del combine_x\n",
    "        del combine_y\n",
    "        \n",
    "        print('Evaluate model...\\n')\n",
    "        score = model.evaluate(test_x, test_y, verbose = 2)\n",
    "        if score[1] > best_score:\n",
    "            model.save_weights('./self_train_best_weights.h5')\n",
    "            best_score = score[1]\n",
    "        else:\n",
    "            model.load_weights('./self_train_best_weights.h5')\n",
    "            lr_ *= 0.3\n",
    "            if lr_ < 1e-7:\n",
    "                lr_ = 1e-5\n",
    "                print(\"learning rate restart to: \", lr_)\n",
    "            else:\n",
    "                print(\"learning rate reduce to: \", lr_)\n",
    "        gc.collect()\n",
    "    return best_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ba36e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 2ms/step\n",
      "threshold: 0.99570614\n",
      "Pseudo label accuracy:  0.9989579715178881\n",
      "Combine data shape:  (3181, 14)\n",
      "Combine label shape:  (3181,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "199/199 - 6s - loss: 0.0266 - accuracy: 0.9903\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 2s - loss: 0.2717 - accuracy: 0.9404\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 1s 10ms/step\n",
      "threshold: 0.9995857\n",
      "Pseudo label accuracy:  0.9924146649810367\n",
      "Combine data shape:  (3466, 14)\n",
      "Combine label shape:  (3466,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "217/217 - 6s - loss: 0.0333 - accuracy: 0.9902\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 2s - loss: 0.2581 - accuracy: 0.8957\n",
      "learning rate reduce to:  3e-05\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 1s 11ms/step\n",
      "threshold: 0.9987418\n",
      "Pseudo label accuracy:  0.9873878923766816\n",
      "Combine data shape:  (3870, 14)\n",
      "Combine label shape:  (3870,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "242/242 - 7s - loss: 0.0185 - accuracy: 0.9922\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 2s - loss: 0.3715 - accuracy: 0.8938\n",
      "learning rate reduce to:  9e-06\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 1s 11ms/step\n",
      "threshold: 0.93602663\n",
      "Pseudo label accuracy:  0.9819233550253073\n",
      "Combine data shape:  (4451, 14)\n",
      "Combine label shape:  (4451,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "279/279 - 8s - loss: 0.0175 - accuracy: 0.9930\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 2s - loss: 0.3268 - accuracy: 0.9404\n",
      "learning rate reduce to:  2.7e-06\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 1s 11ms/step\n",
      "threshold: 0.9006057\n",
      "Pseudo label accuracy:  0.9796719796719797\n",
      "Combine data shape:  (4631, 14)\n",
      "Combine label shape:  (4631,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "290/290 - 8s - loss: 0.0196 - accuracy: 0.9937\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 2s - loss: 0.3106 - accuracy: 0.8741\n",
      "learning rate reduce to:  8.1e-07\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 1s 11ms/step\n",
      "threshold: 0.6566123\n",
      "Pseudo label accuracy:  0.9532913317401694\n",
      "Combine data shape:  (4905, 14)\n",
      "Combine label shape:  (4905,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "307/307 - 6s - loss: 0.0310 - accuracy: 0.9933\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.2978 - accuracy: 0.8741\n",
      "learning rate reduce to:  2.43e-07\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.5745245\n",
      "Pseudo label accuracy:  0.9503067484662576\n",
      "Combine data shape:  (5192, 14)\n",
      "Combine label shape:  (5192,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "325/325 - 6s - loss: 0.0622 - accuracy: 0.9940\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.2789 - accuracy: 0.9409\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "threshold: 0.508163\n",
      "Pseudo label accuracy:  0.937125748502994\n",
      "Combine data shape:  (5646, 14)\n",
      "Combine label shape:  (5646,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "353/353 - 6s - loss: 0.1033 - accuracy: 0.9880\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.2890 - accuracy: 0.8741\n",
      "learning rate restart to:  1e-05\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "threshold: 0.50810134\n",
      "Pseudo label accuracy:  0.9372079985049524\n",
      "Combine data shape:  (5653, 14)\n",
      "Combine label shape:  (5653,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "354/354 - 6s - loss: 0.0640 - accuracy: 0.9880\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.5275 - accuracy: 0.8738\n",
      "learning rate reduce to:  3e-06\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 6s - loss: 0.1302 - accuracy: 0.9539\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.3449 - accuracy: 0.8948\n",
      "learning rate reduce to:  9e-07\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 7s - loss: 0.1396 - accuracy: 0.9567\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.2994 - accuracy: 0.8948\n",
      "learning rate reduce to:  2.6999999999999996e-07\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 6s - loss: 0.1435 - accuracy: 0.9529\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.2857 - accuracy: 0.9409\n",
      "learning rate restart to:  1e-05\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 7s - loss: 0.1154 - accuracy: 0.9539\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.4435 - accuracy: 0.8776\n",
      "learning rate reduce to:  3e-06\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 7s - loss: 0.1305 - accuracy: 0.9511\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.3480 - accuracy: 0.8952\n",
      "learning rate reduce to:  9e-07\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 7s - loss: 0.1390 - accuracy: 0.9555\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.3010 - accuracy: 0.8948\n",
      "learning rate reduce to:  2.6999999999999996e-07\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 7s - loss: 0.1431 - accuracy: 0.9542\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.2852 - accuracy: 0.9409\n",
      "learning rate restart to:  1e-05\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 6s - loss: 0.1143 - accuracy: 0.9544\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.4505 - accuracy: 0.9011\n",
      "learning rate reduce to:  3e-06\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 7s - loss: 0.1306 - accuracy: 0.9544\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.3433 - accuracy: 0.8952\n",
      "learning rate reduce to:  9e-07\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "threshold: 0.5018736\n",
      "Pseudo label accuracy:  0.9415347137637028\n",
      "Combine data shape:  (6049, 14)\n",
      "Combine label shape:  (6049,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 6s - loss: 0.1397 - accuracy: 0.9539\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.2998 - accuracy: 0.8953\n",
      "learning rate reduce to:  2.6999999999999996e-07\n",
      "Predict Pseudo labels...\n",
      "\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "threshold: 0.50101006\n",
      "Pseudo label accuracy:  0.9408901251738526\n",
      "Combine data shape:  (6054, 14)\n",
      "Combine label shape:  (6054,) \n",
      "\n",
      "Tune model using pseudo-labeled data & training data...\n",
      "\n",
      "379/379 - 7s - loss: 0.1443 - accuracy: 0.9524\n",
      "Evaluate model...\n",
      "\n",
      "180/180 - 1s - loss: 0.2845 - accuracy: 0.9409\n",
      "learning rate restart to:  1e-05\n"
     ]
    }
   ],
   "source": [
    "proportion = [0.5, 0.55, 0.6, 0.7, 0.75, 0.8, 0.85, \n",
    "              0.9, 0.93, 0.94, 0.95, 0.96, 0.96, 0.97, 0.97, 0.98, 0.98, 0.99, 0.99, 1]\n",
    "best_score, model = self_train(model, test_x, test_y,\n",
    "                               train_x, train_y, self_train_epoch = 20, model_epoch = 1,\n",
    "                               BATCH = 16, lr_ = 1e-4, best_score = best_score,\n",
    "                               proportion = proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a1c1c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC after Self Training:  0.9408901333808899\n"
     ]
    }
   ],
   "source": [
    "print(\"ACC after Self Training: \", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
